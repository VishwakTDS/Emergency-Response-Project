{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBrLeNmYbPGh"
      },
      "source": [
        "## Installing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vRDoMiTTVYM",
        "outputId": "59c2956c-90db-4b68-e616-777d50827302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current NumPy version: 1.26.4\n",
            "NumPy is already the desired version.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# NumPy fix\n",
        "desired_version = \"1.26.4\"\n",
        "\n",
        "try:\n",
        "    import numpy as np\n",
        "    current_version = np.__version__\n",
        "    print(f\"Current NumPy version: {current_version}\")\n",
        "\n",
        "    if current_version != desired_version:\n",
        "        print(f\"Installing NumPy version {desired_version}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", f\"numpy=={desired_version}\"])\n",
        "\n",
        "        print(\"Restarting runtime to apply changes...\")\n",
        "        os.kill(os.getpid(), 9)\n",
        "    else:\n",
        "        print(\"NumPy is already the desired version.\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"NumPy is not installed. Installing...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", f\"numpy=={desired_version}\"])\n",
        "    os.kill(os.getpid(), 9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p--hLFjmbgmu",
        "outputId": "705e4c55-8c19-4db7-db6a-845cbbed10e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install --quiet \\\n",
        "    chainlit==1.3.2 \\\n",
        "    chromadb==0.5.20 \\\n",
        "    dataclasses-json==0.6.7 \\\n",
        "    fastapi==0.115.5 \\\n",
        "    kaleido==0.2.1 \\\n",
        "    langchain==0.3.0 \\\n",
        "    langchain-chroma==0.1.4 \\\n",
        "    langchain-community==0.3.0 \\\n",
        "    langchain-nvidia-ai-endpoints==0.3.5 \\\n",
        "    langchain-unstructured==0.1.6 \\\n",
        "    protobuf==4.25.2 \\\n",
        "    pydantic==2.9.2 \\\n",
        "    pymupdf==1.25.3 \\\n",
        "    \"unstructured[all-docs]\"==0.17.2 \\\n",
        "    psycopg2-binary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdJ4vCvJ1gxT"
      },
      "source": [
        "# Input API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scK8jidCENOa",
        "outputId": "edd03eac-2d8b-453f-b547-b044eabce72c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NVIDIA API Key is missing or invalid. Please enter a new key.\n",
            "NVIDIA API Key has been successfully set!\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "def set_ngc_api_key():\n",
        "    \"\"\"Prompt the user to enter an NVIDIA API key if it's not set or invalid.\"\"\"\n",
        "    while True:\n",
        "        nvapi_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
        "\n",
        "        if nvapi_key.startswith(\"nvapi-\"):\n",
        "            os.environ[\"NVIDIA_API_KEY\"] = nvapi_key\n",
        "            print(\"NVIDIA API Key has been successfully set!\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid API key. Please try again.\")\n",
        "\n",
        "# Check if the key is already set and valid\n",
        "current_key = os.environ.get(\"NVIDIA_API_KEY\", \"\")\n",
        "\n",
        "if not current_key.startswith(\"nvapi-\"):\n",
        "    print(\"NVIDIA API Key is missing or invalid. Please enter a new key.\")\n",
        "    set_ngc_api_key()\n",
        "else:\n",
        "    print(\"NVIDIA API Key is already set.\")\n",
        "    change_key = input(\"Would you like to enter a different key? (yes/no): \").strip().lower()\n",
        "\n",
        "    if change_key in [\"yes\", \"y\"]:\n",
        "        set_ngc_api_key()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Query the Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import psycopg2\n",
        "\n",
        "conn = psycopg2.connect(\n",
        "    dbname=\"Test-DB\",\n",
        "    user=\"postgres\",\n",
        "    password=\"tdsynnex123\",\n",
        "    host=\"localhost\"\n",
        ")\n",
        "\n",
        "cur = conn.cursor()\n",
        "\n",
        "cur.execute('SELECT we.event_id, we.date, we.location, we.cause, we.area_burned, we.duration, ec.temperature, ec.humidity, ' \\\n",
        "            'ec.wind_speed, ec.precipitation, ra.action_type, ra.resources_used, ra.outcome, hd.lessons_learned, hd.recommendations ' \\\n",
        "            'FROM wildfire_events we ' \\\n",
        "            'JOIN environmental_conditions ec ON we.event_id = ec.event_id ' \\\n",
        "            'JOIN response_actions ra ON we.event_id = ra.event_id ' \\\n",
        "            'JOIN historical_data hd ON we.event_id = hd.event_id;')\n",
        "\n",
        "results = cur.fetchall()\n",
        "\n",
        "cur.close()\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkzOJfZ-t-YU"
      },
      "source": [
        "# Preprocessing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDRTE6T1XZ2Y",
        "outputId": "d2e0e27e-f977-49dc-c418-7e805d0c2230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 2 document elements from the database.\n"
          ]
        }
      ],
      "source": [
        "from langchain.docstore.document import Document\n",
        "\n",
        "documents = []\n",
        "for row in results:\n",
        "    event_id, date, location, cause, area_burned, duration, temperature, humidity, wind_speed, precipitation, action_type, resources_used, outcome, lessons_learned, recommendations = row\n",
        "\n",
        "    # Create a document for each row\n",
        "    content = f\"\"\"\n",
        "    Event ID: {event_id}\n",
        "    Date: {date}\n",
        "    Location: {location}\n",
        "    Cause: {cause}\n",
        "    Area Burned: {area_burned} hectares\n",
        "    Duration: {duration} days\n",
        "    Temperature: {temperature}Â°C\n",
        "    Humidity: {humidity}%\n",
        "    Wind Speed: {wind_speed} km/h\n",
        "    Precipitation: {precipitation} mm\n",
        "    Action Type: {action_type}\n",
        "    Resources Used: {resources_used}\n",
        "    Outcome: {outcome}\n",
        "    Lessons Learned: {lessons_learned}\n",
        "    Recommendations: {recommendations}\n",
        "    \"\"\"\n",
        "\n",
        "    doc = Document(\n",
        "        page_content=content,\n",
        "        metadata={\n",
        "            'source': \"PostgreSQL Database\",\n",
        "            'event_id': event_id\n",
        "        }\n",
        "    )\n",
        "    documents.append(doc)\n",
        "\n",
        "print(f\"Loaded {len(documents)} document elements from the database.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFgT1s2jaDdb"
      },
      "source": [
        "# Generating Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m003DTWPrjq8"
      },
      "outputs": [],
      "source": [
        "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
        "\n",
        "# Create embeddings\n",
        "embedding_model = \"nvidia/nv-embedqa-e5-v5\"\n",
        "embedder = NVIDIAEmbeddings(model=embedding_model, truncate=\"END\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-Otu7D1LH0i"
      },
      "source": [
        "# Storing Embeddings in a Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BwBEuTLvcMq",
        "outputId": "b5715d9c-30fb-489c-aaab-d8daeaf77293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector database was successfully created! Total embeddings indexed: 2\n",
            "--- 2.828407049179077 seconds ---\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "import time\n",
        "\n",
        "# Create and persist vectorstore\n",
        "start_time = time.time()\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embedder,\n",
        "    collection_name=\"docs\",\n",
        "    persist_directory=\"./chroma_db\"\n",
        ")\n",
        "\n",
        "if vectorstore:\n",
        "    print(f\"Vector database was successfully created! Total embeddings indexed: {len(documents)}\")\n",
        "else:\n",
        "    print(\"Failed to create the vector database. Please check your input data.\")\n",
        "\n",
        "print(f\"--- {time.time() - start_time} seconds ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jeOs9_ankrQ"
      },
      "source": [
        "# Adding a Reranker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "53t0R8DYpwf9"
      },
      "outputs": [],
      "source": [
        "from langchain_nvidia_ai_endpoints import NVIDIARerank\n",
        "\n",
        "NV_rerank = NVIDIARerank(model='nvidia/nv-rerankqa-mistral-4b-v3', top_n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoniP_1rNeGD"
      },
      "source": [
        "# Set up the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xCk1bHOjhW9B"
      },
      "outputs": [],
      "source": [
        "question = \"What are the most common causes of wildfires in the dataset?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQnoBI2b0iMe",
        "outputId": "2ca6fa5b-98fb-4ba9-923a-965b997ca7e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\T330082R\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_nvidia_ai_endpoints\\_common.py:212: UserWarning: Found nvidia/llama-3.1-nemotron-ultra-253b-v1 in available_models, but type is unknown and inference may fail.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.schema.runnable import Runnable, RunnablePassthrough, RunnableConfig\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "\n",
        "llm = ChatNVIDIA(model=\"nvidia/llama-3.1-nemotron-ultra-253b-v1\")\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={'k':100})\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Answer solely based on the following context:\\n<Documents>\\n{context}\\n</Documents>\",\n",
        "        ),\n",
        "        (\"user\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "reranker = lambda input: NV_rerank.compress_documents(query=input['question'], documents=input['context'])\n",
        "\n",
        "chain = (\n",
        "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
        "    | {\"context\": reranker, \"question\": lambda input: input['question']}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "gyzbCmkEDbbe",
        "outputId": "b1d8bfe7-ed3a-4722-b3ee-f325917323c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Number of requested results 100 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"<think>\\nOkay, let's look at the documents provided. There are two events here. For Event ID 1, the cause is listed as Lightning. For Event ID 2, the cause is Human Activity. So, there are two different causes, each appearing once. Since the dataset only has two entries, the most common causes would be both, but they occur with the same frequency. So the answer is that the most common causes are Lightning and Human Activity, each occurring once.\\n</think>\\n\\nThe dataset includes two wildfire events with the following causes:\\n\\n1. **Event ID 1**: Cause = **Lightning**  \\n2. **Event ID 2**: Cause = **Human Activity**  \\n\\nBoth causes occur **once**, making them equally the most common in this specific dataset.\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(question)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
